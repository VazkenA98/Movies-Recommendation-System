{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyVVdsT6YEWq"
      },
      "source": [
        "## Similarity Matrices Calculations & Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOP8G-jbxrkF"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "import os\n",
        "from scipy import sparse\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP9VFEWdYEWy"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "globalstart = datetime.now()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_558aMEtYEWy"
      },
      "source": [
        "## 1.  Loading train and test data into dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxDKtKIjYEWz"
      },
      "outputs": [],
      "source": [
        "raw_data_path = \"./data/raw\"\n",
        "movie_titles_csv_path = raw_data_path + \"/movie_titles.csv\"\n",
        "\n",
        "processed_data_path = \"./data/processed\"\n",
        "models_path = \"./models\"\n",
        "master_data_csv_path = processed_data_path + \"/\" + \"data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPz7RGR_xrkM"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpT2WRQjxrlY",
        "outputId": "b6d5ac5c-6c19-49dd-8a09-9d932e3e1c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time Taken: 0:00:00.542682\n"
          ]
        }
      ],
      "source": [
        "start = datetime.now()\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(processed_data_path + \"/\" + \"train_sliced.csv\", parse_dates=['date'])\n",
        "test_df = pd.read_csv(processed_data_path + \"/\" + \"test_sliced.csv\")\n",
        "\n",
        "print(\"Time Taken:\", datetime.now() - start) #Time Taken: 0:00:00.617040"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaPTrRWhYEW2",
        "outputId": "837e21ff-d1a5-43bd-cd9e-6b32c70e333d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>userId</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16242</td>\n",
              "      <td>2248080</td>\n",
              "      <td>3</td>\n",
              "      <td>1999-12-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11064</td>\n",
              "      <td>2248080</td>\n",
              "      <td>3</td>\n",
              "      <td>1999-12-30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId   userId  rating       date\n",
              "0    16242  2248080       3 1999-12-30\n",
              "1    11064  2248080       3 1999-12-30"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsOhDvfUxrnW"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1THmF-sYEW3",
        "outputId": "f49b27e7-7e13-45c5-a5fe-d7f9e263c9ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1150922,), (1150922,), (1150922,))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.userId.values.shape, train_df.movieId.values.shape, train_df.rating.values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvb4BbfJYEW3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Cd1Mv38GxrnX"
      },
      "source": [
        "## 2. Creating sparse matrices from Train and Test Data Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cecn6BdoYEW4"
      },
      "source": [
        "### 2.1. Understanding csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ds3gFYIYYEW4",
        "outputId": "93295819-9387-4f9a-97ab-046e96efdcdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "row = np.array([0, 0, 1, 2, 2, 2])\n",
        "col = np.array([0, 2, 2, 0, 1, 2])\n",
        "data = np.array([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "sparse.csr_matrix((data, (row, col)),).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVWnDx0VYEW5",
        "outputId": "20991636-6949-404e-c803-bb7fd33d0b6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 0, 1, 2, 2, 2]),\n",
              " array([0, 2, 2, 0, 1, 2]),\n",
              " array([1, 2, 3, 4, 5, 6]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "row, col, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_hUFObIYEW5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJhTXsCVxrnZ"
      },
      "source": [
        "### 2.2. Creating sparse matrix from train data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj6TVYrRxrna",
        "outputId": "56d8b6c0-0915-495f-c346-e3f8cb00a72c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is present in your pwd, getting it from disk....\n",
            "DONE..\n",
            "Time taken : 0:00:00.059168\n"
          ]
        }
      ],
      "source": [
        "#Userid as rows and Movie Id as Columns. Ratings as the data in the matrix\n",
        "\n",
        "start = datetime.now()\n",
        "if os.path.isfile(models_path + \"/\" +'train_sparse_matrix.npz'):\n",
        "    print(\"It is present in your pwd, getting it from disk....\")\n",
        "    \n",
        "    train_sparse_matrix = sparse.load_npz(models_path + \"/\" +'train_sparse_matrix.npz')\n",
        "    print(\"DONE..\")\n",
        "else: \n",
        "    print(\"We are creating sparse_matrix from the dataframe..\")\n",
        "    \n",
        "    # create sparse_matrix and store it for after usage.\n",
        "    train_sparse_matrix = sparse.csr_matrix((train_df.rating.values, (train_df.userId.values, train_df.movieId.values)),)\n",
        "    \n",
        "    print('Done. It\\'s shape is : (user, movie) : ',train_sparse_matrix.shape)\n",
        "    print('Saving it into disk for furthur usagemodels..')\n",
        "\n",
        "    sparse.save_npz(models_path + \"/\" + \"train_sparse_matrix.npz\", train_sparse_matrix)\n",
        "    print('Done..\\n')\n",
        "\n",
        "\n",
        "print(\"Time taken :\", datetime.now()-start) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC3exGbRxrne"
      },
      "source": [
        "### 2.3. The Sparsity of Train Sparse Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbN1Wlv_YEW6",
        "outputId": "5ad5e539-ac06-4360-ae36-abefd4d619a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2647889, 17765), 1150922)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sparse_matrix.shape, train_sparse_matrix.count_nonzero()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXQkR5Xhxrng",
        "outputId": "03d9e4d1-ad92-4691-c526-52bd19bd3fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsity Of Train matrix : 99.99755329897192 % \n"
          ]
        }
      ],
      "source": [
        "us,mv = train_sparse_matrix.shape\n",
        "elem = train_sparse_matrix.count_nonzero()\n",
        "\n",
        "print(\"Sparsity Of Train matrix : {} % \".format(  (1-(elem/(us*mv))) * 100) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYOctHZ2xrnn"
      },
      "source": [
        "### 2.4 Creating sparse matrix from test data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZl8EAedxrnq",
        "outputId": "7acb091e-98d5-4412-bed4-b77db5a359f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is present in your pwd, getting it from disk....\n",
            "DONE..\n",
            "Time taken : 0:00:00.033293\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "start = datetime.now()\n",
        "if os.path.isfile(models_path + \"/\" +'test_sparse_matrix.npz'):\n",
        "    print(\"It is present in your pwd, getting it from disk....\")\n",
        "  \n",
        "    test_sparse_matrix = sparse.load_npz(models_path + \"/\" +'test_sparse_matrix.npz')\n",
        "    print(\"DONE..\")\n",
        "else: \n",
        "    print(\"We are creating sparse_matrix from the dataframe..\")\n",
        "    \n",
        "    # create sparse_matrix and store it for after usage.\n",
        "    test_sparse_matrix = sparse.csr_matrix((test_df.rating.values, (test_df.userId.values,\n",
        "                                               test_df.movieId.values)))\n",
        "    \n",
        "    print('Done. It\\'s shape is : (user, movie) : ', test_sparse_matrix.shape)\n",
        "    print('Saving it into disk for furthur usage..')\n",
        "\n",
        "    sparse.save_npz(models_path + \"/\" + \"test_sparse_matrix.npz\", test_sparse_matrix)\n",
        "    print('Done..\\n')\n",
        "    \n",
        "\n",
        "print(\"Time taken :\",datetime.now()-start) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9J75aRtxrnu"
      },
      "source": [
        "### 2.5. The Sparsity of Test data Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYp8qgKXYEW8",
        "outputId": "a8b559e1-8069-4a55-e530-41049a864cf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2647889, 17765), 287731)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_sparse_matrix.shape, test_sparse_matrix.count_nonzero()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzgJhjorxrnz",
        "outputId": "a9e067b5-cc41-4931-af2a-ba366cf857a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsity Of Test matrix : 99.99938832368005 % \n"
          ]
        }
      ],
      "source": [
        "us,mv = test_sparse_matrix.shape\n",
        "elem = test_sparse_matrix.count_nonzero()\n",
        "\n",
        "print(\"Sparsity Of Test matrix : {} % \".format(  (1-(elem/(us*mv))) * 100) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmM8S6yaxroi"
      },
      "source": [
        "## 3. Computing User-User Cosine Similarity Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipdAdhb3xrok"
      },
      "source": [
        "### 3.1. Trying with all dimensions (17k dimensions per user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "CzaXbFY2xrol"
      },
      "source": [
        "Calculating User User Similarity_Matrix is __not very easy__(_unless one has huge Computing Power and lots of time_) because of number of users being large.\n",
        "\n",
        "    * The system could crash or the program stops with **Memory Error**\n",
        "    * Also, significant time would be required. For 100 users itself, it took significant time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5qXgh1eYEW9",
        "outputId": "26ce5b8a-5ee2-4e13-b55f-6a4aaab8b73a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2647889, 17765), 1150922)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sparse_matrix.shape, train_sparse_matrix.count_nonzero()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzc_pANsxron"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "def compute_user_similarity(sparse_matrix, compute_for_few=False, top = 100, verbose=False, verb_for_n_rows = 20,\n",
        "                            draw_time_taken=True):\n",
        "    \n",
        "    no_of_users, _ = sparse_matrix.shape\n",
        "    print('no_of_users:', no_of_users)\n",
        "    \n",
        "    # get the indices of  non zero rows(users) from our sparse matrix\n",
        "    row_ind, col_ind = sparse_matrix.nonzero()\n",
        "    row_ind = sorted(set(row_ind)) # we don't have to\n",
        "    time_taken = list() \n",
        "    \n",
        "    # we create rows, cols, and data lists.., which can be used to create sparse matrices\n",
        "    rows, cols, data = list(), list(), list()\n",
        "    if verbose: print(\"Computing top\",top,\"similarities for each user..\")\n",
        "    \n",
        "    start = datetime.now()\n",
        "    temp = 0\n",
        "    \n",
        "    for row in row_ind[:top] if compute_for_few else row_ind:\n",
        "        temp = temp+1\n",
        "        prev = datetime.now()\n",
        "        \n",
        "        # get the similarity row for this user with all other users\n",
        "        sim = cosine_similarity(sparse_matrix.getrow(row), sparse_matrix).ravel()\n",
        "        # We will get only the top most similar users.\n",
        "        top_sim_ind = sim.argsort()[-top:]\n",
        "        top_sim_val = sim[top_sim_ind]\n",
        "        \n",
        "        rows.extend([row]*top)\n",
        "        cols.extend(top_sim_ind)\n",
        "        data.extend(top_sim_val)\n",
        "        time_taken.append(datetime.now().timestamp() - prev.timestamp())\n",
        "        \n",
        "        if verbose:\n",
        "            if temp%verb_for_n_rows == 0:\n",
        "                print(\"computing done for {} users [  time elapsed : {}  ]\"\n",
        "                      .format(temp, datetime.now()-start))\n",
        "            \n",
        "        \n",
        "    if verbose: print('Creating Sparse matrix from the computed similarities')\n",
        "    \n",
        "    if draw_time_taken:\n",
        "        plt.plot(time_taken, label = 'time taken for each user')\n",
        "        plt.plot(np.cumsum(time_taken), label='Total time')\n",
        "        plt.legend(loc='best')\n",
        "        plt.xlabel('User')\n",
        "        plt.ylabel('Time (seconds)')\n",
        "        plt.show()\n",
        "        \n",
        "    return sparse.csr_matrix((data, (rows, cols)), shape=(no_of_users, no_of_users)), time_taken      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZgRmOS_xrop",
        "outputId": "ae9244a0-cda4-49f6-f14d-d0a9ee958d6e",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is there, We will get it.\n",
            "Done ...\n",
            "It's a  (2647889, 2647889)  dimensional matrix\n",
            "Time taken : 0:00:00.024050\n"
          ]
        }
      ],
      "source": [
        "# Computing User to User Cosine Similarity Matrix \n",
        "start = datetime.now()\n",
        "if not os.path.isfile(models_path + \"/\" + 'u_u_sim_sparse.npz'):\n",
        "    print(\"It seems you don't have that file. Computing movie_movie similarity...\")\n",
        "    start = datetime.now()\n",
        "\n",
        "    u_u_sim_sparse, _ = compute_user_similarity(train_sparse_matrix, compute_for_few=True, top = 100,\n",
        "                                                       verbose=True, verb_for_n_rows=25)\n",
        "\n",
        "\n",
        "    print(\"Done..\")\n",
        "\n",
        "    print(\"Saving it to disk without the need of re-computing it again.. \")\n",
        "    sparse.save_npz(models_path + \"/\" + \"u_u_sim_sparse.npz\", u_u_sim_sparse)\n",
        "    print(\"Done..\")\n",
        "else:\n",
        "    print(\"It is there, We will get it.\")\n",
        "    u_u_sim_sparse = sparse.load_npz(models_path + \"/\" + \"u_u_sim_sparse.npz\")\n",
        "    print(\"Done ...\")\n",
        "    \n",
        "\n",
        "    print(\"It's a \", u_u_sim_sparse.shape,\" dimensional matrix\")\n",
        "\n",
        "    \n",
        "print(\"Time taken :\",datetime.now()-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ6qwEuPYEW-",
        "outputId": "e4455c4f-b771-4314-d71d-ee9659d0292a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2647889, 17765)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sparse_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6HscIstxrot"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slAk4ivQxrou"
      },
      "source": [
        "* We have  **405,041 users** in out training set and computing similarities between them..( **17K dimensional vector..**) is time consuming..\n",
        "\n",
        "\n",
        "- From above plot, It took roughly __8.88 sec__ for computing simlilar users for __one user__\n",
        "    \n",
        "    \n",
        "- We have __405,041 users__ with us in training set.\n",
        "\n",
        "\n",
        "- ${ 405041 \\times 8.88 = 3596764.08  \\sec } =  59946.068 \\min = 999.101133333 \\text{ hours}\n",
        "= 41.629213889 \\text{ days}...$\n",
        "\n",
        "    - Even if we run on high preformance cores parallelly (a typical system now a days), It will still take almost __10 and 1/2__ days. Instead, we will try to reduce the dimentsions using SVD, so that __it might__ speed up the process..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVw4oXVwYEW_"
      },
      "outputs": [],
      "source": [
        "#initilaize the algorithm with some parameters..\n",
        "netflix_svd = TruncatedSVD(n_components=500, algorithm='randomized', random_state=15)\n",
        "trunc_svd = netflix_svd.fit_transform(train_sparse_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cJHgpAtxroy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kI-9jQ7xro9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "for i in ind:\n",
        "    print(\"({}, {})\".format(i, np.round(expl_var[i-1], 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urHM6UzrxrpC"
      },
      "source": [
        " \n",
        "\n",
        "---------\n",
        "\n",
        "-  By just taking __(20 to 30)__ latent factors, explained variance that we could get is __20 %__. \n",
        "\n",
        "- To take it to __60%__, we have to take  __almost 400 latent factors__. It is not fare.\n",
        "\n",
        "\n",
        "\n",
        "- It basically is the __gain of variance explained__, if we ___add one additional latent factor to it.___\n",
        "\n",
        "\n",
        "- By adding one by one latent factore too it, the ___gain in expained variance__ with that addition is decreasing. (Obviously, because they are sorted that way).\n",
        "- ___LHS Graph___:\n",
        "    - __x__ --- ( No of latent factos ),\n",
        "    - __y__ --- ( The variance explained by taking x latent factors)\n",
        "\n",
        "\n",
        "\n",
        "- __More decrease in the line (RHS graph) __:\n",
        "    - We  are getting more expained variance than before.\n",
        "- __Less decrease in that line (RHS graph)__  :\n",
        "    - We are not getting benifitted from adding latent factor furthur. This is what is shown in the plots.\n",
        "\n",
        "\n",
        "- ___RHS Graph___:\n",
        "    - __x__ --- ( No of latent factors ),\n",
        "    - __y__ --- ( Gain n Expl_Var by taking one additional latent factor) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oeIcSxYxrpD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Let's project our Original U_M matrix into into 500 Dimensional space...\n",
        "start = datetime.now()\n",
        "trunc_matrix = train_sparse_matrix.dot(netflix_svd.components_.T)\n",
        "print(datetime.now()- start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAwRD5AwxrpG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "type(trunc_matrix), trunc_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J2zqArKxrpL"
      },
      "source": [
        "* Let's convert this to truncated sparse matrix and store it for future purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zikAa8pkxrpM"
      },
      "outputs": [],
      "source": [
        "# Convertint truncated_matrin into truncated_sparse_matrix and saving it for future use\n",
        "\n",
        "start = datetime.now()\n",
        "if not os.path.isfile(models_path + \"/\" + 'trunc_sparse_matrix.npz'):\n",
        "    \n",
        "    print(\"It seems you don't have that file. Computing...\")\n",
        "\n",
        "    # create that sparse sparse matrix\n",
        "    trunc_sparse_matrix = sparse.csr_matrix(trunc_matrix)\n",
        "    # Save this truncated sparse matrix for later usage..\n",
        "    sparse.save_npz(models_path + \"/\" + 'trunc_sparse_matrix', trunc_sparse_matrix)\n",
        "    \n",
        "    print(\"Done..\")\n",
        "    print(\"Saving it to disk without the need of re-computing it again.. \")  \n",
        "\n",
        "else:\n",
        "    print(\"It is there, We will get it.\")\n",
        "    trunc_sparse_matrix = sparse.load_npz(models_path + \"/\" + 'trunc_sparse_matrix.npz')\n",
        "    print(\"Done..\")\n",
        "        \n",
        "print(\"Time taken:\", datetime.now()-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtMljiarYEXB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V39_Auv4ZnCV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2RFwZgHYEXC"
      },
      "source": [
        "### 3.3: Computing User-User Similarity matrix (Cosine Similarity) for truncated sparse matrix for train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uuo0UeKYEXC"
      },
      "outputs": [],
      "source": [
        "\n",
        "start = datetime.now()\n",
        "if not os.path.isfile(models_path + \"/\" + 'trunc_u_u_sim_matrix.npz'):\n",
        "    print(\"It seems you don't have that file. Computing movie_movie similarity...\")\n",
        "    start = datetime.now()\n",
        "                                           verb_for_n_rows=25)\n",
        "    trunc_u_u_sim_matrix, _ = compute_user_similarity(trunc_sparse_matrix, compute_for_few=False, top=50, verbose=True, \n",
        "                                                 verb_for_n_rows=2500)\n",
        "\n",
        "    print(\"-\"*50)\n",
        "    print(\"Done..\")\n",
        "    print(\"Saving it to disk without the need of re-computing it again.. \")\n",
        "    sparse.save_npz(models_path + \"/\" + \"trunc_u_u_sim_matrix.npz\", trunc_u_u_sim_matrix)\n",
        "    print(\"Done..\")\n",
        "else:\n",
        "    print(\"It is there, We will get it.\")\n",
        "    trunc_u_u_sim_matrix = sparse.load_npz(models_path + \"/\" + \"trunc_u_u_sim_matrix.npz\")\n",
        "    print(\"Done ...\")\n",
        "    \n",
        "print(\"It's a \", trunc_u_u_sim_matrix.shape,\" dimensional matrix\")\n",
        "\n",
        "print(\"Total time:\", datetime.now() - start)\n",
        "\n",
        "# It's a  (2647889, 2647889)  dimensional matrix\n",
        "# 0:00:07.772109"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1ZJOj-RYEXC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL00lDn4YEXC"
      },
      "source": [
        "### 3.4 User User Cosine Similarity Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQR34Tn_YEXC"
      },
      "outputs": [],
      "source": [
        "# Step1: Loading the cosine similarity matrix for truncated sparse matrix\n",
        "\n",
        "trunc_u_u_sim_matrix = sparse.load_npz(models_path + \"/\" + \"trunc_u_u_sim_matrix.npz\")\n",
        "print(\"Loaded ...\")\n",
        "print(\"It's a \", trunc_u_u_sim_matrix.shape,\" dimensional matrix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmtRKLfsYEXC"
      },
      "source": [
        "### 3.4.1 Analysing unique user ids present in the trunc_u_u_sim_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHsykZ_CYEXD"
      },
      "outputs": [],
      "source": [
        "train_df_users = train_df.userId.unique() \n",
        "train_df_users.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x4f-2v7YEXD"
      },
      "outputs": [],
      "source": [
        "sim_matrix_user_ids = np.unique(trunc_u_u_sim_matrix.nonzero()[1]) # Getting all the unique user ids to run them in a loop\n",
        "sim_matrix_user_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcdEMNTQYEXD"
      },
      "outputs": [],
      "source": [
        "user_ids_intersect = np.intersect1d(train_df_users, sim_matrix_user_ids)\n",
        "user_ids_intersect.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bag3fbSJYEXD"
      },
      "outputs": [],
      "source": [
        "temp = np.intersect1d(user_ids_intersect, sim_matrix_user_ids)\n",
        "temp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvWxi8D7YEXE"
      },
      "outputs": [],
      "source": [
        "if 2248080 in sim_matrix_user_ids:\n",
        "    print('Its there!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFmiJKrTYEXE"
      },
      "source": [
        "### 3.4.2 User User Cosine Similarity Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7EBlYxRYEXE"
      },
      "outputs": [],
      "source": [
        "# Finding Simialr users - Number of unique users\n",
        "\n",
        "# The number of users are much more than the number of movies. Hence, finding any similarity for user level will take much more computing time\n",
        "user_ids = np.unique(trunc_u_u_sim_matrix.nonzero()[1]) \n",
        "user_ids.shape, user_ids[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4nWMDZJYEXE"
      },
      "outputs": [],
      "source": [
        "# Checking if the user id is present in the trunc_u_u_sim_matrix\n",
        "\n",
        "# input_user_id = 83\n",
        "input_user_id = 2248080\n",
        "\n",
        "user_is_present = False\n",
        "\n",
        "# Check if user id is present\n",
        "if input_user_id in sim_matrix_user_ids:  \n",
        "    user_is_present = True\n",
        "    print('Its there!!')\n",
        "else:\n",
        "    user_is_present = False\n",
        "    print('Its not there!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i0XcPnPYEXE"
      },
      "outputs": [],
      "source": [
        "user_is_present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1Bf4eG5YEXE"
      },
      "outputs": [],
      "source": [
        "# Finding Simialr users - for a given user id\n",
        "\n",
        "start = datetime.now()\n",
        "similar_users = dict()\n",
        "\n",
        "if user_is_present:\n",
        "    \n",
        "    # get the top five similar similar and store them\n",
        "    sim_users = trunc_u_u_sim_matrix[input_user_id].toarray().ravel().argsort()[::-1][1:]\n",
        "    similar_users[input_user_id] = sim_users[:5]\n",
        "\n",
        "    print(datetime.now() - start)\n",
        "\n",
        "    print(\"Users similar to {} are: \".format(input_user_id), similar_users[input_user_id])\n",
        "else:\n",
        "    print('User is not present!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRnh5z7SYEXF"
      },
      "outputs": [],
      "source": [
        "# Finding User Last Liked movies for a given user id\n",
        "\n",
        "\n",
        "if user_is_present:\n",
        "    # Getting the lastest watched 5 movies which the user has rated 5\n",
        "    rating_options = [5]\n",
        "    num_of_movies = 2  #Number of movies that we want to find\n",
        "\n",
        "    user_last_liked_movies = list(train_df[(train_df['userId'] == input_user_id) & train_df['rating'].isin(rating_options)].tail(num_of_movies).movieId)\n",
        "\n",
        "    print(user_last_liked_movies)\n",
        "else:\n",
        "    print('User is not present!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24im3uQVYEXF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "kb9Yk2f5xrpg"
      },
      "source": [
        "### 3.5: Computing Movie-Movie Similarity matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX24qLe3xrph"
      },
      "outputs": [],
      "source": [
        "start = datetime.now()\n",
        "if not os.path.isfile(models_path + \"/\" + 'm_m_sim_sparse.npz'):\n",
        "    print(\"It seems you don't have that file. Computing movie_movie similarity...\")\n",
        "    start = datetime.now()\n",
        "    m_m_sim_sparse = cosine_similarity(X=train_sparse_matrix.T, dense_output=False)\n",
        "    print(\"Done.. Computed movie movie cosine similarity matrix\")\n",
        "  \n",
        "    print(\"Saving it to disk without the need of re-computing it again.. \")\n",
        "    sparse.save_npz(models_path + \"/\" + \"m_m_sim_sparse.npz\", m_m_sim_sparse)\n",
        "    print(\"Done..\")\n",
        "else:\n",
        "    print(\"It is there, We will get it.\")\n",
        "    m_m_sim_sparse = sparse.load_npz(models_path + \"/\" + \"m_m_sim_sparse.npz\")\n",
        "    print(\"Done ...\")\n",
        "\n",
        "print(\"It's a \",m_m_sim_sparse.shape,\" dimensional matrix\")\n",
        "\n",
        "print(datetime.now() - start)\n",
        "\n",
        "\n",
        "# It seems you don't have that file. Computing movie_movie similarity...\n",
        "# Done.. Computed movie movie cosine similarity matrix\n",
        "# Saving it to disk without the need of re-computing it again.. \n",
        "# Done..\n",
        "# It's a  (17765, 17765)  dimensional matrix\n",
        "# 0:00:01.315013"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwbIOuozxrpn"
      },
      "outputs": [],
      "source": [
        "m_m_sim_sparse.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu8n-HH-YEXG"
      },
      "source": [
        "### 3.6 Movie Movie Cosine Similarity Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3zTb3tiYEXG"
      },
      "source": [
        "### 3.6.1 Analysing unique movie ids present in the m_m_sim_sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzb5_2-qYEXG"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb2DMOQTYEXG"
      },
      "outputs": [],
      "source": [
        "train_df_movies = train_df.movieId.unique()  \n",
        "train_df_movies.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzVeGQoOYEXG"
      },
      "outputs": [],
      "source": [
        "sim_matrix_movie_ids = np.unique(m_m_sim_sparse.nonzero()[1]) # Getting all the unique movie ids to run them in a loop\n",
        "sim_matrix_movie_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkRQrXETYEXH"
      },
      "outputs": [],
      "source": [
        "movie_ids_intersect = np.intersect1d(train_df_movies, sim_matrix_movie_ids)\n",
        "movie_ids_intersect.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AVqMxltYEXH"
      },
      "outputs": [],
      "source": [
        "# Checking if the movie id is present in the m_m_sim_matrix\n",
        "# It will be present only, as we have not done SVD trucation for movie ids\n",
        "\n",
        "input_movie_id = 4670\n",
        "\n",
        "movie_is_present = False  #movie is present in the sparse matrix\n",
        "\n",
        "# Check if user id is present\n",
        "if input_movie_id in sim_matrix_movie_ids:  # Only these users have Cosine Similarity Matrix defined\n",
        "    movie_is_present = True\n",
        "    print('Its there!!')\n",
        "else:\n",
        "    movie_is_present = False\n",
        "    print('Its not there!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XUM2U0iYEXH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZa7_zPqYEXH"
      },
      "outputs": [],
      "source": [
        "\n",
        "start = datetime.now()\n",
        "\n",
        "similar_movies = dict()\n",
        "\n",
        "if movie_is_present:\n",
        "    \n",
        "    # get the top similar movies and store them\n",
        "    sim_movies = m_m_sim_sparse[input_movie_id].toarray().ravel().argsort()[::-1][1:]\n",
        "    similar_movies[input_movie_id] = sim_movies[:100]\n",
        "\n",
        "    print(similar_movies[input_movie_id])\n",
        "\n",
        "else:\n",
        "    print('Movie is not there!!')\n",
        "\n",
        "print(\"Time taken: \",datetime.now() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTEuR2bLYEXH"
      },
      "outputs": [],
      "source": [
        "#  For the user liked movies (approach as required by Gokul)\n",
        "\n",
        "# Aim: Recommend movies based on a user id\n",
        "# Steps:\n",
        "# 1. Find the last n liked movies for a user (which he rated high 4 or 5)\n",
        "# 2. Find movies similar to above n movies, and recommend to the user\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "recommended_movies_user_dict = dict()\n",
        "recommended_movies_user_list = []\n",
        "\n",
        "for movie in user_last_liked_movies:\n",
        "    # get the top similar movies and store them \n",
        "    sim_movies = m_m_sim_sparse[movie].toarray().ravel().argsort()[::-1][1:]\n",
        "    recommended_movies_user_dict[movie] = sim_movies[:10]\n",
        "    recommended_movies_user_list.append(sim_movies[:10])\n",
        "    \n",
        "print(datetime.now() - start)\n",
        "\n",
        "\n",
        "# recommended_movies_user_list\n",
        "t = list(recommended_movies_user_dict.values())\n",
        "flat_list_movie_reco = [item for sublist in t for item in sublist]\n",
        "flat_list_movie_reco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz6WMrAoYEXI"
      },
      "outputs": [],
      "source": [
        "# Adding the movie title as well. Movie details are presnt in movie_titles.csv\n",
        "\n",
        "movie_titles = pd.read_csv(movie_titles_csv_path, names=['movie_id', 'year_of_release', 'title'],  index_col=\"movie_id\", encoding = \"ISO-8859-1\")\n",
        "movie_titles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59vBHmEzYEXI"
      },
      "outputs": [],
      "source": [
        "# Movie Recommendation\n",
        "\n",
        "movie_reco_titles = []\n",
        "\n",
        "for mv_id in flat_list_movie_reco:\n",
        "    movie_title = movie_titles.loc[mv_id].values[1]\n",
        "    movie_year = int(movie_titles.loc[mv_id].values[0])\n",
        "    \n",
        "    movie_reco_titles.append(movie_title)\n",
        "    print('{} : {} ({})'.format(mv_id, movie_title, movie_year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB_LiDL5xrps"
      },
      "outputs": [],
      "source": [
        "\n",
        "start = datetime.now()\n",
        "similar_movies = dict()\n",
        "\n",
        "# Getting all the unique movie ids to run them in a loop\n",
        "movie_ids = np.unique(m_m_sim_sparse.nonzero()[1]) \n",
        "for movie in movie_ids:\n",
        "    # get the top similar movies and store them\n",
        "    sim_movies = m_m_sim_sparse[movie].toarray().ravel().argsort()[::-1][1:]\n",
        "    similar_movies[movie] = sim_movies[:100]\n",
        "print(datetime.now() - start)\n",
        "\n",
        "\n",
        "similar_movies[input_movie_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA1SHx6Oxrpv"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M1QEKCMYEXI"
      },
      "outputs": [],
      "source": [
        "print(\"Total Time taken :\",datetime.now()-globalstart) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W-89x3Hxrp_"
      },
      "source": [
        " "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Step4_Computing Similarity Matrices and Prediction using Cosine Similarity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}